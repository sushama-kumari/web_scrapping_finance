{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA3AUWR0n3sj",
        "outputId": "8f5d69c9-8804-4b78-8cd4-973d07492c72"
      },
      "id": "nA3AUWR0n3sj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fire"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z6UsZiLoCbF",
        "outputId": "c7173c11-3a22-4e28-b56e-a66294bd911d"
      },
      "id": "3Z6UsZiLoCbF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m81.9/88.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire) (2.3.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=8f9082d46856838499aa91b7fb6a920fc3a5b97d1fb1f73c5d4945b13a12e389\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "029e2a1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "029e2a1b",
        "outputId": "a65f3c91-db5e-4821-925e-5e39c5ceb265"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef format_data() -> None:\\n    txt = Path(\\'Q&A_raw.txt\\').read_text()\\n    txt = re.sub(r\"\\x08Q:\\\\s\", \"*Q*: \", txt)\\n    txt.replace(\\'\\n\\', \\'\\')\\n    txt = txt.split(\"*Q*: \")[1:]\\n    qlst = []\\n    alst = []\\n    for pair in txt:\\n        if \"A: \" in pair:\\n            ind = pair.index(\"A: \")\\n            q = pair[:ind]\\n            a = pair[ind + 2:]\\n            qlst.append(q.strip())\\n            alst.append(a.strip())\\n        else :\\n            continue\\n\\n    qa_dict = {\"instruction\":qlst, \"output\":alst}\\n    df = pd.DataFrame(qa_dict)\\n    df[\"input\"] = \"\"\\n    df = df[[\"instruction\", \"input\", \"output\"]]\\n\\n    df_json = pd.read_json(\\'alpaca_data_cleaned.json\\')\\n    df_json = df_json.sample(frac=0.5)\\n\\n    df_qa = pd.read_csv(\"Q&A_raw.csv\")\\n    df_qa[\"instruction\"] = \"\"\\n    df_qa[\"input\"] = [word[2:] for word in df_qa[\"Questions\"]]\\n    df_qa[\"output\"] = [word[2:] for word in df_qa[\"Answers\"]]\\n    df_qa.drop([\"Questions\", \"Answers\"],axis=1, inplace=True)\\n\\n    df_final = pd.concat([df, df_json, df_qa])\\n    df_final.reset_index(inplace=True)\\n\\n    json_list = []\\n    for index, row in df_final.iterrows():\\n        json_list.append({\"instruction\": row[\"instruction\"], \"input\" : row[\"input\"], \"output\": row[\"output\"]})\\n    \\n    with open(\\'final_data.json\\', \\'w\\', encoding=\\'utf-8\\') as f:\\n        json.dump(json_list, f, ensure_ascii=False, indent=2)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\"\"\"\n",
        "run:\n",
        "python -m generate_data generate_instructions_from_websites\n",
        "\"\"\"\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "\n",
        "import openai\n",
        "from openai import openai_object\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import json\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from requests.exceptions import Timeout\n",
        "from typing import Union\n",
        "import fire\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-sk-sk\"\n",
        "#\"sk-sk\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "StrOrOpenAIObject = Union[str, openai_object.OpenAIObject]"
      ],
      "metadata": {
        "id": "OoyvBwrbnofX"
      },
      "id": "OoyvBwrbnofX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_from_url(url: str) -> list[list[str]]:\n",
        "    print(\"inside the function: get_text_from_url\")\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"Skipping {url} due to timeout\")\n",
        "        return []\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    text = [p.text for p in soup.find_all('p') if len(p.text) > 50]\n",
        "\n",
        "    tokens = ' '.join(text).split()\n",
        "\n",
        "    # split page up into x token chunks\n",
        "    truncated_text = split_tokens(tokens, 850)\n",
        "\n",
        "    return truncated_text"
      ],
      "metadata": {
        "id": "eqdiaU0vnhOG"
      },
      "id": "eqdiaU0vnhOG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_tokens(token_list: list[str], max_tokens: int = 1000) -> list[list[str]]:\n",
        "    return [token_list[i:i+max_tokens] for i in range(0, len(token_list), max_tokens)]\n"
      ],
      "metadata": {
        "id": "EldqC0qYncbu"
      },
      "id": "EldqC0qYncbu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_prompt(website: str) -> list[str]:\n",
        "    prompt = open('./prompt.txt', 'r').read()\n",
        "    prompts = []\n",
        "    website_chunks = get_text_from_url(website)\n",
        "    for website_text in website_chunks:\n",
        "        prompts.append(prompt.format(website_text))\n",
        "    return prompts"
      ],
      "metadata": {
        "id": "ThR0nlyNnaB-"
      },
      "id": "ThR0nlyNnaB-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(\n",
        "    website: str,\n",
        "    temperature: float = 0.6,\n",
        "    max_tokens: int = 500,\n",
        "    top_p: float = 1,\n",
        "    n: int = 1,\n",
        "    steam: bool = False,\n",
        "    frequency_penalty: float = 0.1,\n",
        "    presence_penalty: float = 0,\n",
        "    logit_bias={\"50256\": -100},  # prevent the  token from being generated\n",
        ") -> list[StrOrOpenAIObject]:\n",
        "\n",
        "    prompts = encode_prompt(website)\n",
        "    if not prompts:\n",
        "        return []\n",
        "    start_time = time.time()  # measure the start time of the response\n",
        "\n",
        "    responses = []\n",
        "    rpmCount: int = 0\n",
        "    for prompt in prompts:\n",
        "        print(\"NEXT STEP is: openai.ChatCompletion.create\")\n",
        "        rpmCount = rpmCount+ 1\n",
        "        print(\"request count is: \",rpmCount)\n",
        "        if  rpmCount%2 ==0:\n",
        "            print(\"Yes its the 2nd pattern RPM\")\n",
        "            time.sleep(60)\n",
        "            print(\"Scheduled sleep of 60 secs done\")\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {'role': 'user', 'content': prompt}\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens,\n",
        "            top_p=top_p,\n",
        "            n=n,\n",
        "            stream=steam,\n",
        "            frequency_penalty=frequency_penalty,\n",
        "            presence_penalty=presence_penalty,\n",
        "            logit_bias=logit_bias\n",
        "        )\n",
        "        responses.append(response)\n",
        "\n",
        "    end_time = time.time()  # measure the end time of the response\n",
        "\n",
        "    # print the time it took for the response for a website\n",
        "    print(f\" Response Time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    return responses"
      ],
      "metadata": {
        "id": "5vN9M7PYnXWF"
      },
      "id": "5vN9M7PYnXWF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post_process_response(response) -> str:\n",
        "    if not response:\n",
        "        return \"\"\n",
        "\n",
        "    raw_instructions = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    QA_pairs = raw_instructions.split(\"\\n\\n\")\n",
        "\n",
        "    # remove the last QA pair if it's incomplete\n",
        "    if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n",
        "        QA_pairs.pop()\n",
        "\n",
        "    return '\\n\\n'.join(QA_pairs)"
      ],
      "metadata": {
        "id": "LeH_84SKnRzY"
      },
      "id": "LeH_84SKnRzY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_to_df(input: str, df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if not input:\n",
        "        return df\n",
        "\n",
        "    qna_list = input.split('\\n\\n')\n",
        "    new_df = pd.DataFrame(\n",
        "        [qna.split('\\n') for qna in qna_list if len(qna.split('\\n')) == 2], columns=['Questions', 'Answers']\n",
        "    )\n",
        "\n",
        "    result_df = pd.concat([df, new_df], ignore_index=True)\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "4HTY9dJnnNDK"
      },
      "id": "4HTY9dJnnNDK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_raw_data() -> None:\n",
        "    with open(\"./sources.txt\", \"r\", encoding=\"utf-8-sig\") as f:\n",
        "        websites = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    QA_df = pd.DataFrame(columns=['Questions', 'Answers'])\n",
        "    for website in websites:\n",
        "        print(\"website link is: \",website)\n",
        "        responses = get_response(website)\n",
        "        if not responses:\n",
        "            continue\n",
        "        for response in responses:\n",
        "            response_text = post_process_response(response)\n",
        "            QA_df = add_to_df(response_text, QA_df)\n",
        "        print(f\"Total QA pairs: {QA_df.shape[0]}\")\n",
        "    QA_df.to_csv(\"Q&A_raw.csv\", index=False)"
      ],
      "metadata": {
        "id": "DrtJGOVOm6RL"
      },
      "id": "DrtJGOVOm6RL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1def5ebb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1def5ebb",
        "outputId": "5955bee1-86ff-45e7-fe8c-bdf1d648213d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nif __name__ == \"__main__\":\\n    fire.Fire(globals())\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "def generate_instructions_from_websites() -> None:\n",
        "    get_raw_data()\n",
        "   #format_data()\n",
        "\n",
        "\"\"\"\n",
        "if __name__ == \"__main__\":\n",
        "    fire.Fire(globals())\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "76c55cbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76c55cbd",
        "outputId": "ad60b924-1698-4668-9ee6-cd085af5aec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "website link is:  https://www.investopedia.com/personal-finance/most-common-financial-mistakes/\n",
            "inside the function: get_text_from_url\n",
            "NEXT STEP is: openai.ChatCompletion.create\n",
            "request count is:  1\n",
            "NEXT STEP is: openai.ChatCompletion.create\n",
            "request count is:  2\n",
            "Yes its the 2nd pattern RPM\n",
            "Scheduled sleep of 60 secs done\n",
            " Response Time: 91.24 seconds\n",
            "Total QA pairs: 8\n",
            "website link is:  https://www.investopedia.com/articles/pf/09/financial-responsibility.asp\n",
            "inside the function: get_text_from_url\n",
            "NEXT STEP is: openai.ChatCompletion.create\n",
            "request count is:  1\n",
            "NEXT STEP is: openai.ChatCompletion.create\n",
            "request count is:  2\n",
            "Yes its the 2nd pattern RPM\n",
            "Scheduled sleep of 60 secs done\n",
            " Response Time: 88.65 seconds\n",
            "Total QA pairs: 18\n",
            "website link is:  https://www.investopedia.com/personal-finance-calendar-5092591\n",
            "inside the function: get_text_from_url\n",
            "NEXT STEP is: openai.ChatCompletion.create\n",
            "request count is:  1\n",
            "NEXT STEP is: openai.ChatCompletion.create\n",
            "request count is:  2\n",
            "Yes its the 2nd pattern RPM\n",
            "Scheduled sleep of 60 secs done\n",
            " Response Time: 93.19 seconds\n",
            "Total QA pairs: 28\n"
          ]
        }
      ],
      "source": [
        "generate_instructions_from_websites()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}